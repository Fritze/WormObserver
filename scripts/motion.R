# Use this script after running the "data_grouping.R" script that summarises the data for a given condition.
# Needed: A metadata file that is located in the folder that contains the "raw_data.RDS" files generated by the "data_grouping.R" (i.e. the directory that contains the acquired experiments)
# This file should be named "toprocess_motion.txt" and contain the conditions you want to analyse.
# Additionally you have to specify the conversion factor (the number of micrometers that correspond to one pixel at your given magnification, i.e. 6.25).

# To run the script type: Rscript motion.R "the location of your raw data folder" "conversion factor" 
# e.g. Rscript motion.R /media/fpreuss/raid5/timelapses/analysis/paper/raw 6.25

library("tidyverse")

############### functions ###############
#1 Small helper functions

# used to calculate angles describing the worm path
angle1 <- function(x1, y1, x2, y2) {
  values <- list(x1, y1, x2, y2)
  if(anyNA(values)) {
    "NA"
  } else {
    x <- c(x1, y1)
    y <- c(x2, y2)
    dot.prod <- x%*%y
    norm.x <- norm(x,type="2")
    norm.y <- norm(y,type="2")
    theta <- acos(dot.prod / (norm.x * norm.y))
    as.numeric(theta)
  }
}

# used to calculate angles between worm segments
angle2 <- function(x1, y1, x2, y2) {
  atan2(y2,x2) - atan2(y1,x1) 
}

# used to calculate distance change for estimating speed
distance <- function(x1, y1, x2, y2) {
  values <- list(x1, y1, x2, y2)
  if(anyNA(values)) {
    "NA"
  } else {
    length <- sqrt((x1-x2)^2+(y1-y2)^2)
    as.numeric(length)
  }
}

# the function which will change all values of a given column to NA, except those rows that are consecutive for y times
replace_f <- function(x,y){
  subs <- rle(x)
  subs$values[subs$lengths < y] <- NA
  inverse.rle(subs)
}


#2 Calculate centroid tracking statistics per track

centroids_summarise_per_bin <- function(data_input,conversion_factor, offset,binning_factor, max_gaps, duration){
  data_input %>%
    mutate(grouping = paste0(dataset_ID, "_", tp, "_", TrackID)) %>%
    # only tracks with less gaps than max_gaps allowed 
    filter(Number_of_gaps <= max_gaps) %>%
    # only tracks longer than duration
    filter(Duration_of_track >= duration) %>%
    # only tracks above minimal mean velocity value to sort out segmentation artifacts
    filter(Mean_velocity >= min_mean_velocity) %>%
    filter(Duration_of_track >= duration) %>%
    # all calculations now done per individual worm (==track)
    # (uniqueness ensured by grouping by dataset, tp and TrackID)
    group_by(grouping) %>%
    # track displacement as measured by TrackMate times conversion factor to get µm
    mutate(Track_displacement=Track_displacement * conversion_factor) %>%
    # convert frame to second
    mutate(seconds=frame / downsampled_to) %>%
    # create vectors for measuring angle
    # normally: vector one points to position t-1 and vector two points to position t+1
    mutate(x_lag=lag(location_x,n=offset/2) - location_x, y_lag = lag(location_y, n=offset/2) - location_y) %>%
    mutate(x_lead=lead(location_x, n=offset/2) - location_x, y_lead=lead(location_y, n=offset/2) - location_y) %>%
    # calculate the angle and convert to degrees
    #this will result in degrees/s if the offset chosen above corresponds to 1s 
    mutate(angle=suppressWarnings(180 - (as.numeric(mapply(angle1,x_lag,y_lag,x_lead,y_lead)))*180/pi)) %>%
    # mutate(angle=suppressWarnings(as.numeric(mapply(angle2,x_lag,y_lag,x_lead,y_lead)))*(180/pi)) %>%
    # measure distance between current point and 1 second before
    mutate(local_distance=suppressWarnings(as.numeric(mapply(distance,lag(location_x,n=offset),lag(location_y,n=offset),location_x,location_y)))) %>%
    # this will result in velocity based on local distance (µm/s)
    mutate(velocity = local_distance*conversion_factor/downsampled_to) %>%
    # calculate aspect ratio of worm bitmask
    # mutate(aspect_ratio=Minor/Major) %>%
    na.omit() %>%
    #set up binning depending on binning_factor
    mutate(binning=rep(0:n(),each=binning_factor,length.out=n())) %>%
    ungroup() %>%
    na.omit() %>%
    #output will be one row == one bin
    group_by(annotation,TrackID, tp, minutes,dataset_ID,file_name,worm_type,plate_type,Duration_of_track,binning) %>%
    summarise(p_mean_angle = mean(angle),
              p_sd_local_angle=sd(angle),
              p_traveled_distance=sum(local_distance),
              p_mean_velocity = mean(velocity),
              p_size = mean(Size),
              p_omega_rf = sum(Prediction == "turn" & Prediction_confidence > 0.8)) %>%
    #append selected parameters to each row
    mutate(offset = offset,
           max_gaps = max_gaps,
           duration = duration,
           binning_factor = binning_factor)
}

#######################################################


#get file path from command line
dataraw_file_path <- commandArgs(trailingOnly = TRUE)[1]
conversion_factor <- as.numeric(commandArgs(trailingOnly = TRUE)[2])
#set parameters
#We record at 2fps
offset =2 #== 1 seconds
# offset <- as.numeric(commandArgs(trailingOnly = TRUE)[3])
max_gaps = 0
# max_gaps <- as.numeric(commandArgs(trailingOnly = TRUE)[4])
duration = 20 #==10 seconds
# duration <- as.numeric(commandArgs(trailingOnly = TRUE)[5])
binning_factor = 20 #==10 seconds
# binning_factor <- duration <- as.numeric(commandArgs(trailingOnly = TRUE)[6])
min_mean_velocity = 5

#create file path for saving
save_path <- file.path(dirname(dataraw_file_path),"motion")
#create the save path directories
dir.create(save_path,recursive = TRUE)
#catch toprocess_motion.txt location
toprocess_file_path <- file.path(file.path(dataraw_file_path, "toprocess_motion.txt"))


#extract list of datasets to process from "toprocess_motion.txt" file
list_of_datasets <- as.matrix(read.table(toprocess_file_path))
files_to_process <- paste0(paste0(file.path(dataraw_file_path,list_of_datasets),"_raw_data.rds"))
# print(files_to_process)


#list of .rds files in data folder that were already analysed for centroid tracking
names_already_processed <- unique(gsub(".+\\/(.+)\\_centroid.+","\\1",list.files(save_path, "centroid_tracking", full.names = TRUE, ignore.case = TRUE)))
files_already_processed <- paste0(paste0(file.path(dataraw_file_path,names_already_processed),"_raw_data.rds"))

if(length(files_already_processed) > 0){
  #remaining annotations to process
  files_to_process_cleaned <- files_to_process[!files_to_process %in% files_already_processed]
} else {
  files_to_process_cleaned <- files_to_process
}
#print(files_to_process_cleaned)
#get file path
if (length(files_to_process_cleaned) > 0){
  number_files_to_process <- length(files_to_process_cleaned)
  cat("The following files will be processed:\n", paste(files_to_process_cleaned, collapse = "\n"))
  # for each of these files calculate the centroid tracking statistics
  for (file in files_to_process_cleaned){
    cat("\n\nNow processing: ", file)
    imported_data <- readRDS(file)
    annotation <- unique(imported_data$annotation)
    annotation_underscored <- gsub(" ", "_", annotation)


    #calculate centroid tracking statistics per bin
    centroids_tracking_bins <- centroids_summarise_per_bin(imported_data,conversion_factor,offset,binning_factor,max_gaps,duration)
    created_file_path <- file.path(save_path,paste0(annotation_underscored,"_centroid_tracking_bins.RDS"))
    number_files_to_process <<- number_files_to_process - 1
    saveRDS(centroids_tracking_bins, file=created_file_path)
    cat(paste0("\n\nCentroids tracked, averaged over bins. \nDataset ", file, " was processed\nand saved under ", created_file_path, "\n", number_files_to_process, " datasets waiting to be processed.\n\n"))


    rm(imported_data)
    gc()
  }
}else{
  cat("All datasets in ", dataraw_file_path," already processed.")
}
