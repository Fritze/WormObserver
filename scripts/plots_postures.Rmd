
#Select files to load
#We need the clustering file containing the mean positions of each cluster as well as the skeletons filtered file with clusters attached
```{r, include=FALSE}

target_folder<-"/home/fpreuss/raid/timelapses/analysis/200318/data/posture"
save_path <- "/home/fpreuss/raid/timelapses/analysis/200318/plots/posture"


skeletons_filtered_clustered_filepath <- list.files(path = target_folder,pattern="200417.+skeletons_filtered_clustered.RDS",ignore.case = TRUE, full.names = TRUE)
clustering_filepath <- list.files(path = target_folder,pattern="200417.+clustering.RDS",ignore.case = TRUE, full.names = TRUE)
cluster_centers_reduced_filepath <- list.files(path = target_folder,pattern="200417.+_cluster_centers_reduced.RDS",ignore.case = TRUE, full.names = TRUE)

cluster <- readRDS(clustering_filepath)
cluster_centers_reduced <- readRDS(clusters_centers_reduced_filepath)
skeleton_data_clustered <- readRDS(skeletons_filtered_clustered_filepath)
```



#calculate relative occurence of clusters
#also calculate different ordering vectors (based on posture frequency or similarity)
```{r, include=FALSE}

#add clusters to initial skeleton dataset that was used for kmeans clustering
#also calculate relative occurences of postures (i.e. clusters) both total and per annotation
freq_postures <- skeleton_data_clustered %>%
  #select only relevant columns
  select(newID,annotation) %>%
  #do this now for every newID and annotation independently
  group_by(newID, annotation) %>%
  summarise(counts_annotation = n()) %>%
  #do this now for every annotation independently
  group_by(annotation) %>%
  #occurences of all clusters together == total_annotation
  mutate(total_annotation = sum(counts_annotation)) %>%
  mutate(perc_annotation = counts_annotation/total_annotation * 100) %>%
  group_by(newID) %>%
  mutate(counts_all = sum(counts_annotation)) %>%
  mutate(total_all = sum(total_annotation)) %>%
  ungroup() %>%
  mutate(perc_all = counts_all/total_all * 100)
```


#calculate posture occurences
```{r, include=FALSE}
freq_postures_overall <- freq_postures %>%
  group_by(newID,perc_all) %>%
  summarise() %>%
  arrange(desc(perc_all)) %>%
  ungroup() %>%
  mutate(rank_all = 1:n())

ggplot(freq_postures_overall,aes(x=rank_all,y=perc_all))+
  geom_col()+
  labs(x="Posture Rank", y="Probability (%)")+
  theme_linedraw()
  

#order by overall occurence
order_overall <- freq_postures_overall$newID


```

#Plot every frame of a random track
#plotted will be the original skeleton (with original X and Y location), as well as the alligned skeleton and the corresponding posture
```{r, include=FALSE}

#list of all tracks
list_of_tracks <- skeleton_data_clustered %>%
  mutate(dataset_TrackID =  paste0(dataset_ID,"_",tp,"_",TrackID)) %>%
  distinct(dataset_TrackID) %>%
  pull(dataset_TrackID)


#select a random track from this list
random_track <- sample(list_of_tracks,1)

                                      
#subset random track and turn the skeletons
skeleton_data_clustered_subset <- skeleton_data_clustered %>%
  mutate(dataset_TrackID =  paste0(dataset_ID,"_",tp,"_",TrackID)) %>%
  filter(dataset_TrackID == random_track) %>%
  group_by(ID) %>%
  #keep old X and Y positions (before turning) to compare when plotting
  mutate(X_original = X, Y_original = Y) %>%
  group_modify(~ turn_worm(.x))
  


#plot all frames from list of frames of the random track
for (i in unique(skeleton_data_clustered_subset$frame)){
   
  selected_frame <- i 
  #temporary subset (only skeleton of selected frame)
  skeleton_data_clustered_subset_temp <- skeleton_data_clustered_subset %>%
    filter(frame == selected_frame)
  
  #clusterID of selected skeleton
  clusterID_to_plot <- unique(skeleton_data_clustered_subset_temp$clusterID)
  #corresponding cluster center
  cluster_centers_reduced_temp <- cluster_centers_reduced %>%
    filter(clusterID == clusterID_to_plot)
  
  #plot raw with old X and Y coordinates
  plot_raw <- plot_posture_examples(skeleton_data_clustered_subset_temp, "X_original", "Y_original")+
   geom_point(data=filter(skeleton_data_clustered_subset_temp,index == 2), aes_string("X_original","Y_original"),color="orange",size=8,shape=16) + 
    theme(plot.caption = element_text(vjust = -3),
          legend.position = "none")+
    ggtitle(paste0("Raw ", random_track,", frame ", selected_frame))
    
  #plot turned worm
  plots_alligned <- plot_posture_examples(skeleton_data_clustered_subset_temp,"X","Y") +
    geom_point(data=filter(skeleton_data_clustered_subset_temp,index == 2), aes(X,Y),color="orange",size=5,shape=16) +
    ggtitle(paste0("Alligned"))+
    theme(plot.caption = element_text(vjust = -3),
          legend.position = "none")
  
  #plot corresponding cluster center
  plot_corresponding_cluster_mean <- plot_posture_examples(cluster_centers_reduced_temp,"X","Y") +
    geom_point(data=filter(cluster_centers_reduced_temp,index == 2), aes_string("X","Y"),color="orange",size=5,shape=16) +
    ggtitle(paste0("Posture ", clusterID_to_plot))+
    theme(plot.caption = element_text(vjust = -3),
          legend.position = "none")
  
  #bring all together
  ((plot_raw + plot_spacer()) |
    plots_alligned/
    plot_corresponding_cluster_mean) +
    plot_layout(heights = unit(c(6,1,8,8), c('cm', 'cm','cm','cm')))+
    # plot_layout(widths=c(1,3,3), heights = c(1,3, 3))
     ggsave(file.path(save_path,paste0("posture_frame",selected_frame,".png")),height=15,width=10)

}

```


#Calculate relative occurence of postures per hour
```{r, include=FALSE}

angle_data_postures_first <-  skeleton_data_clustered %>%
  #round to half hour steps
  # mutate(hours_rounded = ceiling(minutes/60*2)/2) %>%
  #round to full hour steps
  mutate(hours_rounded = ceiling(minutes/60)) %>%
  mutate(dataset_TrackID =  paste0(dataset_ID,"_",tp,"_",TrackID)) %>%
  ###
  # group_by(annotation,dataset_TrackID,hours_rounded) %>%
  # nest() %>%
  # group_by(annotation,hours_rounded) %>%
  # sample_n(80) %>%
  # unnest(cols=c(data)) %>%
  ## group_by(annotation,hours_rounded,dataset_TrackID) %>%
  ## summarise(n_tracks = n_distinct(dataset_TrackID),n_total = n())
  # group_by(annotation,ID,dataset_TrackID,hours_rounded) %>%
  # nest() %>%
  # group_by(annotation,hours_rounded,dataset_TrackID) %>%
  ## summarise(n=n_distinct(ID))
  # sample_n(20) %>%
  # unnest(cols=c(data)) %>%
  # group_by(annotation,hours_rounded) %>%
  # summarise(n_tracks = n_distinct(dataset_TrackID),n_postures = n_distinct(ID))
  ###
  #reduce dataset
  group_by(ID,newID,annotation,hours_rounded,dataset_ID,dataset_TrackID) %>%
  summarise() %>%
  #do this for every newID, timepoint and annotation
  group_by(newID,hours_rounded,annotation) %>%
  #number of clusters per timepoint and experiment
  mutate(number_of_cluster_members_per_tp=n_distinct(ID)) %>%
  group_by(newID,hours_rounded,annotation,dataset_ID) %>%
  #number of clusters per timepoint and experiment
  mutate(number_of_cluster_members_per_tp_per_dataset=n_distinct(ID)) %>%
  arrange(newID) %>%
  #do this for every timepoint and annotation
  group_by(hours_rounded,annotation) %>%
  #total number of postures per timepoint and annotation
  mutate(postures_per_tp=n_distinct(ID)) %>%
  #total number of tracks per timepoint and annotation
  mutate(tracks_per_tp=n_distinct(dataset_TrackID)) %>%
  #percentage per annotation
  mutate(perc = number_of_cluster_members_per_tp/postures_per_tp) %>%
  #do this for every timepoint and annotation
  group_by(hours_rounded,dataset_ID) %>%
  #total number of postures per timepoint and dataset_ID
  mutate(postures_per_tp_per_dataset=n_distinct(ID)) %>%
  #total number of tracks per timepoint and dataset_ID
  mutate(tracks_per_tp_per_dataset=n_distinct(dataset_TrackID)) %>%
  #percentage per dataset_ID  
  mutate(perc_per_dataset = number_of_cluster_members_per_tp_per_dataset/postures_per_tp_per_dataset) %>%
  group_by_at(vars(-ID,-dataset_TrackID)) %>%
  summarise() %>%
  ungroup()

#Posture quantified over time per annotation (i.e. type of experiment)
angle_data_postures <- angle_data_postures_first %>%
  select(-dataset_ID) %>%
  select(-contains("per_dataset")) %>%
  group_by_all() %>%
  summarise() %>%
  #do this for every cluster and annotation  (i.e. over all timepoints)
  group_by(newID,annotation) %>%
  mutate(sd_perc = sd(perc)) %>%
  mutate(rM = rollmean(perc, 2, fill=NA)) %>%
  mutate(sd_rM = sd(rM,na.rm = TRUE)) %>%
  mutate(mean_perc = mean(perc)) %>%
  mutate(mean_rM = mean(rM, na.rm=TRUE)) %>%
  mutate(perc_norm = (perc-mean_perc)/sd_perc) %>%
  mutate(rM_norm = (rM-mean_rM)/sd_rM) %>%
  ungroup() %>%
  filter(hours_rounded <= 9) %>%
  arrange(newID,hours_rounded,annotation)

#Posture quantified over time per dataset_ID (i.e. per experiment replicate)
angle_data_postures_per_dataset <- angle_data_postures_first %>%  
  #do this for every cluster and dataset_ID (not grouped as annotation)  (i.e. over all timepoints)
  group_by(newID,dataset_ID) %>%
  mutate(sd_perc_per_dataset = sd(perc_per_dataset)) %>%
  mutate(rM_per_dataset = rollmean(perc_per_dataset, 2, fill=NA)) %>%
  mutate(sd_rM_per_dataset = sd(rM_per_dataset,na.rm = TRUE)) %>%
  mutate(mean_perc_per_dataset = mean(perc_per_dataset)) %>%
  mutate(mean_rM_per_dataset = mean(rM_per_dataset, na.rm=TRUE)) %>%
  mutate(perc_norm_per_dataset = (perc_per_dataset-mean_perc_per_dataset)/sd_perc_per_dataset) %>%
  mutate(rM_norm_per_dataset = (rM_per_dataset-mean_rM_per_dataset)/sd_rM_per_dataset) %>%
  ungroup() %>%
  filter(hours_rounded <= 9) %>%
  arrange(newID,hours_rounded,annotation,dataset_ID)

```

```{r, include=FALSE}


plot_posture_heatmap <- function(data_to_plot,order){
  ggplot(data_to_plot,aes(x=factor(newID,levels=order),y=hours_rounded))+
  theme_classic()+
  labs(x="posture IDs",y = "hours",fill="Z-score") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  theme(axis.text.y = element_text(size = 30,face = "bold"),
        axis.text.x = element_text(size = 30),
        axis.title.x = element_text(size=45),
        axis.title.y = element_text(size=45),
        strip.text = element_text(size=45),
        legend.text=element_text(size=50),
        legend.title = element_text(size=50),
        legend.key.size = unit(2, "cm"),
        legend.position = "right",
        legend.direction='vertical')+
  coord_equal()
}

plot_posture_examples <- function(data_to_plot,X,Y){
  ggplot(data_to_plot, aes_string(x=X,y=Y,color="angle"))+
    geom_point(size=6) +
    geom_path(size=5,lineend = "round") +
    theme_void()+
    coord_fixed(ratio = 1)+
    scale_color_gradient2(low = "deepskyblue", mid = "lavender",
                          high = "deeppink",midpoint=0,limits=c(-1,1),na.value="grey") +
    # scale_color_viridis(option = "plasma",limits=c(-1,1))+
    theme(plot.title = element_text(face = "bold"))
}

#get all annotations
annotations <- c(unique(angle_data_postures$annotation))
normalizations <- c("perc","perc_norm","rM_norm")



for (a in annotations){
  for (n in normalizations){
  temporal_clustering <- angle_data_postures %>%
    filter(annotation == a) %>%
    na.omit() %>%
    dcast(newID ~ hours_rounded,value.var = n) %>%
    tibble::column_to_rownames(var = "newID")
  
  #cluster the temporal posture patterns with the current normalization
  temporal_clustering <- temporal_clustering[order(as.numeric(rownames(temporal_clustering))),,drop=FALSE]
  #this ordering from the hclsut is the rowID, it is NOT the actual posture ID
  ordering <- hclust(dist(temporal_clustering, method = "euclidean"), method = "average")$order
  #get posture ID by their rownumber 
  ordering <- as.numeric(rownames(temporal_clustering)[ordering])
  
  #generate heatmap data
  #normaliazion column will be the one for the current normalization
  heatmap_data_to_plot <- angle_data_postures %>%
    filter(annotation == a) %>%
    rename(normalization =  all_of(n))
  
  #generate heatmap
  heatmap <- plot_posture_heatmap(heatmap_data_to_plot,ordering) +
    geom_tile(aes(fill=normalization))+
    scale_fill_distiller(type = "div",limits=c(-1,1) * max(abs(select(heatmap_data_to_plot,normalization))))+
    # scale_fill_distiller(palette="PiYG",limits=c(-1,1) * max(abs(select(heatmap_data_to_plot_per_dataset,normalization_per_dataset))))+
    scale_y_continuous(breaks=seq(1,max(heatmap_data_to_plot$hours_rounded),2))
  
  #generate heatmap data per dataset
  heatmap_data_to_plot_per_dataset <- angle_data_postures_per_dataset %>%
    filter(annotation == a)  %>%
    rename(normalization_per_dataset =  paste0(all_of(n),"_per_dataset"))
  
 plot_posture_heatmap(heatmap_data_to_plot_per_dataset,ordering) +
    geom_tile(aes(fill= normalization_per_dataset))+
    scale_fill_distiller(type = "div",limits=c(-1,1) * max(abs(select(heatmap_data_to_plot_per_dataset,normalization_per_dataset))))+
    # scale_fill_distiller(palette="PiYG",limits=c(-1,1) * max(abs(select(heatmap_data_to_plot_per_dataset,normalization_per_dataset))))+
    facet_wrap(vars(dataset_ID),ncol=1)+
    scale_y_continuous(breaks=seq(1,max(heatmap_data_to_plot_per_dataset$hours_rounded),2))+
    ggsave(file.path(save_path,paste0("200407_heatmap_",a,"_",n,"_per_dataset",".png")),width=40,height=30)
  
  #levels must be changed for ggplot to take new order into account
  cluster_centers_reduced$newID = factor(cluster_centers_reduced$newID, levels=ordering)
  
  #generate all postures, for the mirrored ones show only newID_sub
  skeletons <- plot_posture_examples(filter(cluster_centers_reduced,newID_sub == 1), "X","Y") +
    geom_point(data=filter(cluster_centers_reduced,index == 2 & newID_sub == 1), aes(X,Y),color="orange",size=5,shape=17) +
    facet_wrap(vars(newID),ncol=6) +
    theme(strip.text.x = element_text(size = 45,face="bold"))
  
  heatmap /
    skeletons + 
    plot_layout(widths = c(1,8),heights = c(1,8)) +
    ggsave(file.path(save_path,paste0("200417_heatmap_",a,"_",n,".png")),width=40,height=30)
  
  
  
  }
}


```













